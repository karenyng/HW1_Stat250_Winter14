{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Author: Karen Yin-Yee Ng \n",
      "\n",
      "Stat 250 Winter 2014  Assignment 1 part 1 \n",
      "\n",
      "Written with an ipython notebook (v 1.1.0)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autosave 60"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "IPython.notebook.set_autosave_interval(60000)"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Autosaving every 60 seconds\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. method: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We benchmark different approaches for computing the statistics of airline delays between 1987 to 2012. \n",
      "\n",
      "* exact approach 1: use shell to computate the entire frequency table of counts of unique delay values then use R / Python to do the statistics\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1.1 Shell scripting part"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observation: there are two types of files with two different headers. The month-by-month csv has one type of header and the year-by-year ones have a different type.\n",
      "\n",
      "Implementation of shell script for extracting columns from the csv files is quite straight forward except that, in the month-by-month csv, there are some values with \",\" in them, making the naive use of cut with \",\" as delimiter fail to fetch the correct column. My quick and dirty solution is to increment the column number count by 2 as a correction.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Manual testing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See 'exam_col.sh' and 'test.ipynb' : the bash script only fetch column and outputting to txt files. It helps for verifying if the columns are fetched correctly for each type of the two types of csv. I then compute the mean in this file and compare the expected result using python dataframes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Other possible tests that I do not have time for: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* output all the headers of the year-by-year csv and do diff on them to make sure they all really share the same format.\n",
      "\n",
      "* output all the headers of the month-by-month csv and do diff on them to make sure they all really share the same format."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Striping the header "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. R scripting part "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "How to prevent numerical inaccuracies for computing the statistics:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a sense of the order of magnitude of the numbers that we are computing : The total unique frequency count is $\\omega_{total} =  $\n",
      "\n",
      "For R, the maximum value that an integer can hold is $\\sim 10^9$, and double can hold much larger integer $\\sim 10^{308}$. Machine precision for double is $\\sim 10^{-16}$. \n",
      "\n",
      "Since we have a very lax requirement for the precision (up to one minute), we shouldn't have to worry too much about cancellation errors."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Computing the mean:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Danger of overflow of this naive formula:\n",
      "\n",
      "$$ \\bar{t} = \\frac{ \\sum_i^n (t_i ~\\omega_i)}{\\omega_{total}}$$\n",
      "\n",
      "where $\\omega$ denotes the count and $t$ denotes the delay time."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we don't a have huge amount of data, maybe switching to double precision for holding the sum will avoid the problem just fine and we may still be able use the naive summation. (because the max integer that a double can hold is much larger). \n",
      "Since we have huge amount of data, switching to using double precision will increase the use of memory (by two times?) and I am still not sure if it can avoid overflow. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a safety precaution I will compute the mean using \n",
      "\n",
      "$$ \\bar{t} =  \\sum_i^n \\frac{(t_i ~\\omega_i)}{\\omega_{total}}$$\n",
      "\n",
      " By multiplying before dividing, there shouldn't be any underflow problems."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Computing the std. dev. - Adaptation of the Welford method:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Computing the median:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Almost trivial."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2. Results:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "......eyeballing if answer make sense by plotting the frequency counts"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Computation time:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have coded up two different versions of the bash script. \n",
      "First version collect the columns from different csv and write them all out to a big file before sorting then counting frequencies. \n",
      "I expect the I/O to be one of the bigger bottlenecks.\n",
      "\n",
      "Second version tries to create an array to hold all the relevant columns then perform sorting and dropping duplicates. The second approach avoids I/O but may use up more memory due to my lack of good way of growing arrays.\n",
      "\n",
      "I could also do the "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wallclock time of the approach: \n",
      "this excludes downloading the data \n",
      "\n",
      "Wallclock time of completing this assignment:\n",
      "\n",
      "\n",
      "\n",
      "CPU time: \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Machine specification:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Corsair Vengeance 2x8GB DDR3 1600 MHz Desktop Memory, \n",
      "* Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, http://ark.intel.com/products/75123\n",
      "* GeForce GTX 770 SuperClocked\n",
      "* Samsung 840 Pro 256 GB SSD\n",
      "* Motherboard: Asus Z87-Deluxe DDR3 1600 LGA 1150 \n",
      "* Linux Mint 15 Olivia (GNU/Linux 3.8.0-19-generic x86_64)\n",
      "* R version 3.0.2 (2013-09-25) -- \"Frisbee Sailing\"\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bonus question:\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How did Duncan download the data off of the following website?\n",
      "http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ans (trying to gain some extra brownie points):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Short answer: download & start reading from P.333 of  http://link.springer.com/book/10.1007%2F978-1-4614-7900-0\n",
      "\n",
      "Long answer: I could guesstimate how to fill in the dynamic form on that website with some scripts and pull the links to those forms for downloading the data. But I will just get back to working on the other parts of the homework... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Acknowledgement(s) / reference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to an anonymous physicist in Portland who has kindly allowed me to use his gaming desktop for the computing of this homework. He helped me repair the partition table to my Linux partition and installed a HDD for use."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}