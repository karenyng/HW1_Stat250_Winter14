


% Header, overrides base

    % Make sure that the sphinx doc style knows who it inherits from.
    \def\sphinxdocclass{article}

    % Declare the document class
    \documentclass[letterpaper,10pt,english]{/usr/local/lib/python2.7/dist-packages/sphinx/texinputs/sphinxhowto}

    % Imports
    \usepackage[utf8]{inputenc}
    \DeclareUnicodeCharacter{00A0}{\\nobreakspace}
    \usepackage[T1]{fontenc}
    \usepackage{babel}
    \usepackage{times}
    \usepackage{import}
    \usepackage[Bjarne]{/usr/local/lib/python2.7/dist-packages/sphinx/texinputs/fncychap}
    \usepackage{longtable}
    \usepackage{/usr/local/lib/python2.7/dist-packages/sphinx/texinputs/sphinx}
    \usepackage{multirow}

    \usepackage{amsmath}
    \usepackage{amssymb}
    \usepackage{ucs}
    \usepackage{enumerate}

    % Used to make the Input/Output rules follow around the contents.
    \usepackage{needspace}

    % Pygments requirements
    \usepackage{fancyvrb}
    \usepackage{color}
    % ansi colors additions
    \definecolor{darkgreen}{rgb}{.12,.54,.11}
    \definecolor{lightgray}{gray}{.95}
    \definecolor{brown}{rgb}{0.54,0.27,0.07}
    \definecolor{purple}{rgb}{0.5,0.0,0.5}
    \definecolor{darkgray}{gray}{0.25}
    \definecolor{lightred}{rgb}{1.0,0.39,0.28}
    \definecolor{lightgreen}{rgb}{0.48,0.99,0.0}
    \definecolor{lightblue}{rgb}{0.53,0.81,0.92}
    \definecolor{lightpurple}{rgb}{0.87,0.63,0.87}
    \definecolor{lightcyan}{rgb}{0.5,1.0,0.83}

    % Needed to box output/input
    \usepackage{tikz}
        \usetikzlibrary{calc,arrows,shadows}
    \usepackage[framemethod=tikz]{mdframed}

    \usepackage{alltt}

    % Used to load and display graphics
    \usepackage{graphicx}
    \graphicspath{ {figs/} }
    \usepackage[Export]{adjustbox} % To resize

    % used so that images for notebooks which have spaces in the name can still be included
    \usepackage{grffile}


    % For formatting output while also word wrapping.
    \usepackage{listings}
    \lstset{breaklines=true}
    \lstset{basicstyle=\small\ttfamily}
    \def\smaller{\fontsize{9.5pt}{9.5pt}\selectfont}

    %Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    %Set pygments styles if needed...
    
        \definecolor{nbframe-border}{rgb}{0.867,0.867,0.867}
        \definecolor{nbframe-bg}{rgb}{0.969,0.969,0.969}
        \definecolor{nbframe-in-prompt}{rgb}{0.0,0.0,0.502}
        \definecolor{nbframe-out-prompt}{rgb}{0.545,0.0,0.0}

        \newenvironment{ColorVerbatim}
        {\begin{mdframed}[%
            roundcorner=1.0pt, %
            backgroundcolor=nbframe-bg, %
            userdefinedwidth=1\linewidth, %
            leftmargin=0.1\linewidth, %
            innerleftmargin=0pt, %
            innerrightmargin=0pt, %
            linecolor=nbframe-border, %
            linewidth=1pt, %
            usetwoside=false, %
            everyline=true, %
            innerlinewidth=3pt, %
            innerlinecolor=nbframe-bg, %
            middlelinewidth=1pt, %
            middlelinecolor=nbframe-bg, %
            outerlinewidth=0.5pt, %
            outerlinecolor=nbframe-border, %
            needspace=0pt
        ]}
        {\end{mdframed}}
        
        \newenvironment{InvisibleVerbatim}
        {\begin{mdframed}[leftmargin=0.1\linewidth,innerleftmargin=3pt,innerrightmargin=3pt, userdefinedwidth=1\linewidth, linewidth=0pt, linecolor=white, usetwoside=false]}
        {\end{mdframed}}

        \renewenvironment{Verbatim}[1][\unskip]
        {\begin{alltt}\smaller}
        {\end{alltt}}
    

    % Help prevent overflowing lines due to urls and other hard-to-break 
    % entities.  This doesn't catch everything...
    \sloppy

    % Document level variables
    \title{hw1}
    \date{January 22, 2014}
    \release{}
    \author{Unknown Author}
    \renewcommand{\releasename}{}

    % TODO: Add option for the user to specify a logo for his/her export.
    \newcommand{\sphinxlogo}{}

    % Make the index page of the document.
    \makeindex

    % Import sphinx document type specifics.
     


% Body

    % Start of the document
    \begin{document}

        
            \maketitle
        

        


        
        Author: Karen Yin-Yee Ng
\href{mailto:karenyng@ucdavis.edu}{karenyng@ucdavis.edu}

Stat 250 Winter 2014 with Prof.~Duncan Temple Lang

Assignment 1

Written with an ipython notebook (v 1.1.0)

    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}1{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}}\PY{k}{autosave} \PY{l+m+mi}{60}
\PY{o}{\PYZpc{}}\PY{k}{load\PYZus{}ext} \PY{n}{nbtoc}
\PY{o}{\PYZpc{}}\PY{k}{nbtoc}
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
            \end{InvisibleVerbatim}
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}Autosaving every 60 seconds
\end{alltt}

            \end{InvisibleVerbatim}
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
            \end{InvisibleVerbatim}
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
            \end{InvisibleVerbatim}
            
        
    
\part{Methods}We benchmark different approaches for computing the statistics of
airline delays between 1987 and 2012.

Design considerations, due to the large size of the data, we have to :

\begin{itemize}
\item
  avoid holding all the data in memory at same time but only want to
  extract the relevant data
\item
  avoid numerical instabilities
\item
  make it fast - avoid expensive operations such as making copies of
  data or I/O to hard disk

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    may want to make it parallelizable depending on performance
  \end{itemize}
\end{itemize}

Other possible consideration if this was made into a production code:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  extensibility
\end{itemize}\part{Exact approach 1}\subsection{frequency table approach using the shell \& R (or item 5)}Pros:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  development time is faster than using any of the compiled language (
  other than probably python for me)
\item
  one of the shortest implementation in terms of lines of code
\item
  no fancy algorithms are needed
\item
  good for prototyping which is what usually people do in industry
\item
  super cool that the shell can do so much stuff so fast with so little
  code
\end{itemize}

Cons:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  runtime may be slower than using pure compiled language for doing
  string manipulation
\item
  the computation of the frequency table is not the most parallelizble
\item
  some implementation for fetching column values were hackish - not very
  extensible
\item
  a lot of the parameters are hard coded
\item
  not a good production / extensible code due to the above cons
\end{itemize}

Other thoughts about implementation:

Not going to write the code in the most general / extensible /
parallelizable way but I focus on getting an estimate of the answer from
this first method

I usually write code as functions and use OOP concepts but I don't have
time for this.\section{Shell scripting part}Observation: there are two types of files with two different headers.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  month-by-month csv\\
\item
  year-by-year csv
\end{itemize}extracting columns from the csv files is quite straight forward except
that, in the month-by-month csv, there are some values with ``,'' in
them, making the naive use of cut with ``,'' as delimiter fail to fetch
the correct column. My quick and dirty solution is to increment the
column number count by 2 as a correction.\subsection{Manual testing}I made sure that the functions work on individual files before looping
them over more files. Test codes are called `exam\_col.sh' and
`test.ipynb'\subsection{Other possible tests that I do not have time for:}\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  output all the headers of the year-by-year csv and month-by-month csv
  and make sure there are no variety within each type of csv
\end{itemize}

Also, on second thought I should have written a test code, using python
or R to write out mean, median and standard deviation for each of the
csv files.

Then also use my code to write output of same format. Then just use diff
in the shell to check if there is any differences to check for as many
possible exceptional cases as possible.

Now I'm just manually comparing statistics of individual files / writing
out fake data for testing.

I really should have done a better job planning for unit tests
\ldots{}\ldots{}\section{R part - computing the statistics}When I write in a scripting language, I usually

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  keep code short
\item
  avoid loops and use vectorized operations
\end{itemize}

Since R is not particularly strong in string manipulation or
``developers of R did not have string manipulation in mind when they
designed R'' (Temple Lang 2014), I try to keep all string operations
within the shell script.\subsection{Considerations for preventing numerical inaccuracies with the frequency
table approach:}To get a sense of the order of magnitude of the numbers that we are
computing :

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  total unique frequency count is $\omega_{total} \sim 10^8$
\item
  range of the delay time around {[}-1437, 2598{]}
\item
  all delay time are integers which simplifies that problem by a lot
\item
  precision requirement is lax (up to one minute - I will report the
  answer with one or two more decimal places at most or else we are over
  confident about the precision of the data)
\end{itemize}

Of course these stats are obtained after I have run them through my
scripts. On second thought I should have find/guesstimate the properties
of the data before deciding on what languages / tools to use for this
homework.

For R,

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  the maximum value that an integer can hold is $\sim 10^9$, and
\item
  double can hold much larger integer $\sim 10^{308}$ and is the default
  R data type for numbers
\item
  Machine precision for double is $\sim 10^{-16}$.
\end{itemize}

Since R uses double for storing the ArrDelay field by default and data
take integer form, we really shouldn't have to worry too much about
numerical inaccuracies like overflow (when summing number), underflow
(dividing by large number) or cancellation error (subtraction). I argue
we do not need more rigorous algorithms in the world for just computing
the statistics of ArrDelay with the frequency table approach. If we
compute the statistics with other methods, we may have to worry more,
especially when computing the standard deviation.\subsubsection{Computing the mean:}danger of loss of accuracies of this naive formula???

\[ \bar{t} = \frac{ \sum_i^n (t_i ~\omega_i)}{\omega_{total}}\]

where $t_i$ denotes the delay time $\omega_i$ denotes the corresponding
count for that $t_i$. Numerator may overflow if we are just summing a
bunch of positive numbers that are too large, but some of the numbers in
the summation are negative.As a safety precaution I will compute the mean using

\[ \bar{t} =  \sum_i^n \frac{(t_i ~\omega_i)}{\omega_{total}}\]

Note $t_i, w_i \ll w_{total}$, by multiplying before dividing, there
shouldn't be any underflow problems. And also I am using the default R
sum() method which uses partial sums so I think it should be accurate
enough.\subsubsection{Computing the std. dev.:}After reading John Cook 's entry I decide to use an adapted version of
the two-pass formula because

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  I have already computed total frequency
\item
  it is not less accurate
\item
  I can write vectorized code instead of using Welford's recursive
  formula in R (looping is slow and recursion performance may be worse
  than looping)
\end{itemize}

\[s = \sqrt{\sum_i^n \frac{w_i}{w_{total}}(t_i - \bar{t})^2} \]\subsubsection{Computing the median:}I tested total frequency count is odd or even to avoid grabbing the
wrong median.\section{How to call the code:}Create a directory in the git directory called data then move all the
csv files inside the data directory\begin{quote}
Rscript
\end{quote}\section{Results of method 1 :}\begin{quote}
mean = 6.(566504) min
\end{quote}

\begin{quote}
median = 0.(00000) min
\end{quote}

\begin{quote}
standard deviation = 31.(556326) min
\end{quote}

should probably just report up to 1 or 2 significant figure(s).\ldots{}\ldots{}eyeballing if answer make sense by plotting the
frequency counts Maybe I should have made bar plots but I am just trying
to quickly visualize this.

Being able to visualize the results is a great strength of the frequency
table approach

    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}18{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot}
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    


    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}19{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{c}{\PYZsh{} somehow pandas has trouble reading the sorted frequency table}
\PY{n}{a} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{sorted\PYZus{}freq.txt}\PY{l+s}{\PYZdq{}}\PY{p}{,} \PY{n}{names} \PY{o}{=} \PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{col}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)} 
\PY{n}{c} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{a}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{n}{b} \PY{o}{=} \PY{n}{a}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{col}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}
    \PY{k}{if} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{b}\PY{p}{)} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{n}{b}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{l+s}{\PYZsq{}}\PY{l+s}{NA}\PY{l+s}{\PYZsq{}}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{b}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{!=}\PY{l+s}{\PYZsq{}}\PY{l+s}{ArrDelay}\PY{l+s}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{n}{c}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{b}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n+nb}{float}\PY{p}{(}\PY{n}{b}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{c} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{c}\PY{p}{)}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{p}{)}

\PY{n}{delay} \PY{o}{=} \PY{n}{c}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
\PY{n}{freq} \PY{o}{=} \PY{n}{c}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    


    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}20{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{delay}\PY{p}{,} \PY{n}{freq}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{.b}\PY{l+s}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Delay time (min)}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Frequency}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
\PY{n}{xlim\PYZus{}low} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{100}
\PY{n}{xlim\PYZus{}high} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Truncated view of frequency table from}\PY{l+s}{\PYZsq{}}\PY{o}{+}\PYZbs{}
          \PY{l+s}{\PYZsq{}}\PY{l+s}{\PYZob{}0\PYZcb{} to \PYZob{}1\PYZcb{}}\PY{l+s}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{xlim\PYZus{}low}\PY{p}{,} \PY{n}{xlim\PYZus{}high}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{n}{xlim\PYZus{}low}\PY{p}{,} \PY{n}{xlim\PYZus{}high}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{6.566504}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{mean}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{r}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{ls} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{:}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{lw} \PY{o}{=} \PY{l+m+mi}{3} \PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{0.00}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{median}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{g}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{ls} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{\PYZhy{}\PYZhy{}}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{lw} \PY{o}{=} \PY{l+m+mi}{3} \PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{best}\PY{l+s}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-out-prompt}Out\hspace{4pt}{[}20{]}:\hspace{4pt}}\\*
                \vspace{-2.55\baselineskip}\begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}<matplotlib.legend.Legend at 0x3af1fd0>\end{alltt}

            \end{InvisibleVerbatim}
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
    \begin{center}
    \includegraphics[max size={\textwidth}{\textheight}]{hw1_files/hw1_33_1.png}
    \par
    \end{center}
    
            \end{InvisibleVerbatim}
            
        
    


    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}21{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{delay}\PY{p}{,} \PY{n}{freq}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{.b}\PY{l+s}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Delay time (min)}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Frequency}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
\PY{n}{xlim\PYZus{}low} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{100}
\PY{n}{xlim\PYZus{}high} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Total view of frequency table}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{6.566504}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{mean}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{r}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{ls} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{:}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{lw} \PY{o}{=} \PY{l+m+mi}{3}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{0.00}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{median}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{color} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{g}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{ls} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{\PYZhy{}\PYZhy{}}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{lw} \PY{o}{=} \PY{l+m+mi}{3} \PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{best}\PY{l+s}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-out-prompt}Out\hspace{4pt}{[}21{]}:\hspace{4pt}}\\*
                \vspace{-2.55\baselineskip}\begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}<matplotlib.legend.Legend at 0x41dd190>\end{alltt}

            \end{InvisibleVerbatim}
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
    \begin{center}
    \includegraphics[max size={\textwidth}{\textheight}]{hw1_files/hw1_34_1.png}
    \par
    \end{center}
    
            \end{InvisibleVerbatim}
            
        
    
It makes sense that the mean is slightly positive which is explained by
the longer tail on the positive end.

It also makes sense that the median could be at zero, the positive tail
is offset by the taller and fatter peak on the negative end if you look
at the truncated plot.

Standard deviation is also plausible given the long tails.\section{Computation time: \textasciitilde{}5 mins}This is probably not the fastest approach in terms of CPU time.

Possible improvement in the bash script: the bash script grabs the
columns from different csv and write them all out to a big file before
sorting then counting frequencies. I expect the I/O to hard disk to be
one of the bigger bottlenecks. Dynamic arrays in the shell can be used
to remedy this but I am not familiar how bash handles the memory for
growing array to comment on if it will not use up a lot of memory.

Also the computation of the frequency table is also a place for possible
improvements. Currently I have sorted all the 500 MB of ArrDelay column
data before using ``uniq'' to compute the frequency table. If we can
implement a fast hashing method then we might be able to avoid holding
all 500MB of data. Even though 500 MB data should not be a limiting
factor for even laptop as old as 5 years old but if the data is bigger
than this is not an extensible solution.\section{Memory usage:}Negligible amount of swap was used as far as I am concerned\part{Exact Method 2: Python with Pandas and Numpy (calling compiled code from
python)}\section{Background:}This implementation is probably the most straight forward with only
around 47 lines.

Python pandas is a data analysis python package that imitates R syntax
and it has a C backend highly optimized for speed. I took a quick look
at the relevant source code on github. The relevant C / Cython code are
scattered in mainly in
\url{https://github.com/pydata/pandas/tree/master/pandas} and
\url{https://github.com/pydata/pandas/tree/master/pandas/src}

The actual ``python'' implementation of the read.csv function looks like
it is mostly in Python:
\url{https://github.com/pydata/pandas/blob/master/pandas/io/parsers.py}
BUT, it is naive to think the read.csv function is really written in
python since it imported a bunch of libraries to replace original Python
parts. For example the imported pandas.lib
\url{https://github.com/pydata/pandas/blob/master/pandas/lib.pyx} seems
to replace the python data variables such as integers, nans, infs with C
variables and make calls to C standard libraries.

here 's an excerpt of parsers.py where the calls to wrapped libraries
are made:\begin{verbatim}
import pandas.lib as lib
import pandas.tslib as tslib
import pandas.parser as _parser
\end{verbatim}\subsection{What my code does:}\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  loop over all the csv files , extracting only relevant column
\item
  first extract columns of the year-by-year csv into one pandas
  dataframe then the month-by-month csv into another pandas dataframe
\item
  remove the ``column name'' of each dataframe by turning them to numpy
  arrays
\item
  concatenate them together using numpy.append() -- this is NOT slow
  since Python libraries pass most objects by reference not by value
\item
  convert them back to pandas dataframe since a dataframe can handle nan
  values automatically, numpy array handles nan more clumsily
\item
  call existing methods of pandas dataframe to compute mean, median and
  standard deviation
\end{itemize}Pros of this method:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  short and simple
\item
  fast
\item
  extensible - pandas can do subsetting and group by and apply functions
  very easily, and also handles NA among other things. If you want a
  different field you can just grab that column by changing the script
  by one variable.
\end{itemize}

Cons of this method:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  most of the code is hidden away from me so if pandas developer has a
  bug somewhere it is harder for me to debug
\item
  code compatibility of future pandas version is at the mercy of pandas
  developers -- I better document exactly the version I am using in case
  pandas change drastically in the future
\end{itemize}\subsection{Tests of the code}\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  informative with print statements
\item
  results agree with first method
\end{itemize}\section{Runtime of method 2: \textasciitilde{}3.1 min}user system elapsed 89.872 16.604 185.723\section{How to call the code}\begin{quote}
Rscript
\end{quote}\part{Method 3 - Approximate approach using FastCSVSample}\subsection{Background}The idea is to reduce the amount of data to be analyzed by sampling
uniformly across all the csv files using
https://github.com/duncantl/FastCSVSample

Therefore in the coding process, it is important to ensure the (almost)
same percentages of lines are sampled from each csv file. Since I do not
usually do sampling as a physics student I would like to see what
percentage of lines I need to sample in order to get results close to
the exact method.\subsection{Design considerations:}Ideally the code should:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  have O(n) run time at most where n is the sampled number of lines

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    this needs running statistics to be computed\\
  \end{itemize}
\end{itemize}

*\subsection{How to run the code:}\begin{quote}
Rscript
\end{quote}Or you can download and run the forked R package NotSoFastCSVSample (pun
intended).\part{Machine specification:}\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Corsair Vengeance 2x8GB DDR3 1600 MHz Desktop Memory,
\item
  Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, 
\item
  GeForce GTX 770 SuperClocked
\item
  Samsung 840 Pro 256 GB SSD
\item
  Motherboard: Asus Z87-Deluxe DDR3 1600 LGA 1150
\item
  Linux Mint 15 Olivia (GNU/Linux 3.8.0-19-generic x86\_64)
\item
  R version 3.0.2 (2013-09-25) -- ``Frisbee Sailing''
\item
  Python v. 2.7.4, numpy v.1.7.1, pandas v.0.10.1
\end{itemize}

Thanks to an anonymous physicist in Portland who has kindly allowed me
to use his gaming desktop for the computing of this homework. He helped
me repair the partition table to my Linux partition and installed a HDD
for use.\part{Discussion}\section{Comparison of results of different methods}\section{Comparison of runtime of different methods}\section{Relevant packages for R that can also extract specific columns from a
csv file:}After googling around it seems like there are also packages in R that
can read csv files with specified columns. Such as:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  colbycol on CRAN
\item
  limma on Bioconductor
\end{itemize}

So it is possible to do the computation purely in R without having to
use the shell. It would be interesting to compare the speeds between a
``pure R'' implementation with these packages vs the ``pure Python''
implementation with pandas and numpy. It concerns me that R seems to
pass by value if I try to use the same approach as my python code to
append the data frames. The memory usage will definitely be more than my
python implementation. Or maybe I will just have to adapt the R version
in a different style than my python code.\section{What If I can't overcome the temptation of using a compiled language}I would choose C++ over C since C++ has a regex library and more
complete OOP features. Speed of C and C++ are comparable. Regex and C++
strings will save some headache for fetching headers that are not
exclusive to ArrDelay for extensibility. Also, it is easily to extend
the code for different type of variables. I would be able to write C++
templates to handle columns of different variable types and use
polymorphism. (sounds really fun and I will probably spend way too much
time just optimizing it)\part{Actual code:}\section{Method 1: shell script to compute entire frequency table then use R to
compute statistics}(I do not like how the cat command messes with the indentation of my
bash script but here it is)

    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}24{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}cat ../freq\PYZus{}count.sh
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}\#!/bin/bash

\#---------------------------------------------------------------------
------
\# Author: Karen Ng
\# This script
\# * reads in airline csv data files
\# * finds the column that corresponds to delay time
\# * cut the column then count the frequencies of a certain delay time
\# * returns frequency count in files named 1.txt 2.txt etc.
\# * the frequency count files still has header and NA values mixed
inside
\# * have to use R or other language to discard those
\# version 1: no growing arrays but have slow I/O
\#---------------------------------------------------------------------
------

shopt -s nullglob
dir="./data"
\# store all file names in a bash array
files=( "\$dir"/*.csv )
fileno=\$\{\#files[*]\}

\# check for csv input error
if [ \$\{fileno\} -eq 0 ]; then
        echo "--------SHELL SCRIPT ERROR-----------------------------"
        echo "ERROR: no suitable *.csv file found in \$PWD/data"
        echo "For this script to work, put *.csv files in \$PWD/data"
        echo "-------------------------------------------------------"
        exit 0;
fi

\# loop through the files one by one
for ((j=0; j < \$\{fileno\}; j++));
do
        \# look at the header, split them by "," then store in array
        arr=(\$(head -1 \$\{files[\$j]\} | tr "," "\textbackslash{}n"))
        arrLen=\$\{\#arr[*]\}
        col=-99

        \# loop through array of headers and count which column it is
in
        for ((i=0; i < \$\{arrLen\}; i++));
        do
                x=\$\{arr[\$i]\}
                if [ \$x == "ArrDelay" ] || [ \$x == "\textbackslash{}"ARR\_DELAY\textbackslash{}"" ];
then
                        \# definition of column count is off by 1
between bash array and cut
                        col=\$i
                        (( col += 1 ))

                        \# if it is a monthly csv, have to add two to
the column count for the
                        \# column value to be fetched correctly by cut.
                        \# This is because some values in the monthly
CSV contain commas
                        if [ \$x == "\textbackslash{}"ARR\_DELAY\textbackslash{}"" ]; then
                                (( col += 2 ))
                        fi

                        break
                fi
        done

        \#echo "Writing the file-\$j delay time to freq\_count.txt"
        \# store the frequency count of all the csv files in one single
file
        \# possible time improvement:
        \# use an array to hold these instead of writing it to a file
first
        \# the col-finding and the writing out takes around 1 min 8 s
real time
        if [ \$j -eq 0 ]; then
                cut -d',' -f\$\{col\} \$\{files[\$j]\} > freq\_count.txt
        else
                cut -d',' -f\$\{col\} \$\{files[\$j]\} >> freq\_count.txt
        fi

done

\# pipe the content of frequency count to sed
\# use sed to remove the trailing decimal places for some delay time
entries
\# sort them then find unique counts
\# remove header --- could have just used grep -v
cat freq\_count.txt | sed -E 's/([0-9]+)\textbackslash{}.00/\textbackslash{}1/g' |\textbackslash{}
        sort -n | uniq -c |\textbackslash{}
        sed -e '/ArrDelay/d' -e '/ARR\_DEL15/d'

\# can output to a text file to check values
\#> sorted\_freq.txt
\end{alltt}

            \end{InvisibleVerbatim}
            
        
    


    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}25{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}cat ../method1.R
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}\#---------------------------------------------------------------------
-
\# Author: Karen Ng
\# Purpose:
\# reads in a two column file with frequency of each entry and entry
value
\#---------------------------------------------------------------------

run <- function()\{
  col.names <- c('freq', 'delay')
  print("First method: compute\_stat.R: ")
  print("computing and reading in sorted frequency table from bash
script")
  print("This takes \textasciitilde{}5 mins for a 3.5 GHz machine with sufficient
RAM")
  \# call the shell script for cutting columns and doing frequency
count
  DF <- try(read.table(pipe("./freq\_count.sh"), col.names = col.names,
                            fill = TRUE), silent=TRUE)
  if (class(DF) == "try-error")\{
    print("ERROR: failed to read in \$PWD/data/*.csv")
    print("USAGE: place data in \$PWD/data/*.csv for this script to
work")
    q("no", 1, FALSE)
  \}
  \# REMOVE NAN!!!
  DF <- na.omit(DF)

  print("compute\_stat.R")
  print("compute\_stat.R: computing total frequencies")
  w.total <- sum(DF[['freq']])
  print("total number of valid total frequency count")
  print(w.total)

  print("compute\_stat.R: computing mean")
  t.mean <- sum(DF[['freq']] * ( DF[['delay']] / w.total), na.rm =
TRUE)

  print("compute\_stat.R: computing median")
  i <- 1
  Sum <- DF[['freq']][i]
  medianFreqCount <- floor(w.total / 2)
  \#\# sorry don't know better than to write a loop\ldots
  while(Sum < medianFreqCount) \{
    i <- i + 1
    \# this vectorized operation
    Sum <- sum(DF[['freq']][1:i], na.rm = TRUE)
    \# is faster than
    \#\# if ( !is.na(DF[['freq']][i]) ) \{
    \#\#   Sum <- Sum + DF[['freq']][i]
    \#\# \}
  \}
  \#\# check for corner case:
  \#\# or else there the median will may be off
  print("compute\_stat.R: computing standard dev.")
  if( Sum == medianFreqCount \&\&  w.total \%\% 2 == 0)\{
    \# print("going through special case")
    t.median <- (DF[['delay']][i] + DF[['delay']][i+1])/2
  \}else\{
    t.median <- DF[['delay']][i]
  \}

  \# after reading Jook Cook 's entry on computation of std. dev
  \# I decide to go with the (two-pass) direct method  because this can
be
  \# written entirely in vectorized form
  std.dev <- sqrt(sum(DF[['freq']] * (DF[['delay']] - t.mean) \^{} 2 /
(w.total-1)))
  results1 <- c(t.mean, t.median, std.dev)
  \#print(results)
  results1
\}

time.method1 <- system.time(results1 <- run())
save(results1, time.method1, file="results1.rda")
\end{alltt}

            \end{InvisibleVerbatim}
            
        
    
\section{Method 2: Python + Pandas + Numpy (calling a compiled language)}

    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}26{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}cat ../compute\PYZus{}stat.py
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}\#!/usr/bin/env python

import pandas as pd
import numpy as np

data\_path = "./data/"

\# First read in the data from 1987 to 2007
year = [ str(i) for i in range(1987,2008) ]
\# create empty dataframe
delay1 = pd.DataFrame()
\# loop through the year-by-year csvs
for yr in year:
    \# read in relevant column from csv file using pandas
    file = yr +'.csv'
    temp = pd.read\_csv(data\_path + file, usecols=["ArrDelay"])
    \# append the dataframes - this is done by reference not by value
    delay1 = delay1.append(temp)
    print 'appending '+ file + ' - total lines = ' + \textbackslash{}
            '\{0\}'.format(delay1.shape[0])

\# create another empty dataframe for handling month by month csv
delay2 = pd.DataFrame()
year = [ str(i) for i in range(2008, 2013) ]
month = ['January','February', 'March', 'April', 'May', 'June',
'July',
         'August','September', 'October', 'November', 'December']
\# loop through all the month-by-montyh csv
for yr in year:
    for mth in month:
        file = yr + '\_' + mth + '.csv'
        \# tell pandas to read only the relevant column in the csv
        temp = pd.read\_csv(data\_path + file, usecols=["ARR\_DELAY"])
        \# append them to the dataframe by reference
        delay2 = delay2.append(temp)
        print 'appending ' + file + ' - total lines = ' + \textbackslash{}
            '\{0\}'.format(delay2.shape[0] + delay1.shape[0])

\# hackish way to remove the column name of the dataframe to append
\# the two types of csv columns together
\# so I can compute the statistics in one pass later on
delay1 = np.array(delay1)
delay2 = np.array(delay2)
delay = np.append(delay1, delay2)
delay = pd.DataFrame(delay)
print 'total number of valid lines =
\{0\}'.format(delay.dropna().shape[0])

\# note that pandas ignores nans automatically while computing stats
\#print 'mean = \{0\} \textbackslash{}n'.format(delay[0].mean()) +\textbackslash{}
\#    'median = \{0\} \textbackslash{}n'.format(delay[0].median()) +\textbackslash{}
\#    'std. dev. = \{0\}\textbackslash{}n'.format(delay[0].std())

print 'saving to results2.txt'
f = open('results2.txt', 'w')
f.write('mean = \{0\}\textbackslash{}n'.format(delay[0].mean()))
f.write('median = \{0\}\textbackslash{}n'.format(delay[0].median()))
f.write('std = \{0\}\textbackslash{}n'.format(delay[0].std()))
f.close()
\end{alltt}

            \end{InvisibleVerbatim}
            
        
    
In this python code I don't even have to do exception handling since
Pandas is so smart.

    % Make sure that atleast 4 lines are below the HR
    \needspace{4\baselineskip}

    
        \vspace{6pt}
        \makebox[0.1\linewidth]{\smaller\hfill\tt\color{nbframe-in-prompt}In\hspace{4pt}{[}27{]}:\hspace{4pt}}\\*
        \vspace{-2.65\baselineskip}
        \begin{ColorVerbatim}
            \vspace{-0.7\baselineskip}
            \begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}cat ../method2.R
\end{Verbatim}

            
                \vspace{-0.2\baselineskip}
            
        \end{ColorVerbatim}
    

    

        % If the first block is an image, minipage the image.  Else
        % request a certain amount of space for the input text.
        \needspace{4\baselineskip}
        
        

            % Add document contents.
            
                \begin{InvisibleVerbatim}
                \vspace{-0.5\baselineskip}
\begin{alltt}\#---------------------------------------------------------------------
-
\# Author: Karen Ng
\# Purpose:
\# R wrapper around python code so there would be consistent profiling
\#---------------------------------------------------------------------
time.method2 <- system.time(system("./compute\_stat.py"))
\# read in results from python script
con = file("./results2.txt","r")
results2 <- readLines(con)
save(results2, time.method2, file="results2.rda")

\end{alltt}

            \end{InvisibleVerbatim}
            
        
    
\section{Method 3: (NotSo)FastCSVSample}In this method I forked Duncan's FastCSVSample R package and added some
R code (which might have made it not so fast).

Since we are sampling from files with quite different sizes, it is
important that we sample approximately a fixed percentage of lines.\section{Miscellaneous : Bonus question}How did Duncan download the data for use in this homework ?
\url{http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236}Short answer: download \& start reading Duncan's new book from P.333 of
\url{http://link.springer.com/book/10.1007\%2F978-1-4614-7900-0}

Long answer: I could guesstimate how to fill in the dynamic form on that
website with some scripts and pull the links to those forms for
downloading the data. But I will just get back to working on the other
parts of the homework\ldots{}
        

        \renewcommand{\indexname}{Index}
        \printindex

    % End of document
    \end{document}


